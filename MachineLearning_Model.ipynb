{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML packages\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json file\n",
    "original_df = pd.read_json(\"/Users/bach/Documents/MP3-Project/complete_df_creation/music_vector_metadata.json\")\n",
    "\n",
    "# Because there are duplicates in column name so we will drop it\n",
    "original_df.drop_duplicates(subset=['track_id'],inplace=True)\n",
    "\n",
    "# We only take vector and characteristic columns\n",
    "unclean_df = original_df[['vector', 'characteristic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57712 entries, 0 to 66530\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   vector          57712 non-null  object\n",
      " 1   characteristic  46329 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values \n",
    "unclean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bhh3_bkx79339d96vvxv8b4h0000gn/T/ipykernel_82580/907424595.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unclean_df.dropna(subset=['characteristic'], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Drop N/A values in the characteristic\n",
    "unclean_df.dropna(subset=['characteristic'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 46329 entries, 4 to 66530\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   vector          46329 non-null  object\n",
      " 1   characteristic  46329 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>characteristic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.8194460272789, 0.10938329249620402, 0.4214...</td>\n",
       "      <td>quirky, eclectic, abstract, energetic, passion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.823113977909088, -0.23747463524341503, 0.2...</td>\n",
       "      <td>introspective, melancholic, energetic, summer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.8000821471214291, -0.11462888121604901, 0....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[-0.660261571407318, -0.089793100953102, 0.160...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[-0.722541749477386, 0.068502597510814, 0.2457...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[-0.8456231951713561, -0.12404702603816901, 0....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[-0.742057025432586, 0.010221602395176001, 0.2...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[-0.8483147025108331, -0.09521148353815001, 0....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[-0.7372666597366331, 0.06824257969856201, 0.4...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.7887574434280391, -0.095258809626102, 0.09...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               vector  \\\n",
       "4   [-0.8194460272789, 0.10938329249620402, 0.4214...   \n",
       "5   [-0.823113977909088, -0.23747463524341503, 0.2...   \n",
       "8   [-0.8000821471214291, -0.11462888121604901, 0....   \n",
       "9   [-0.660261571407318, -0.089793100953102, 0.160...   \n",
       "10  [-0.722541749477386, 0.068502597510814, 0.2457...   \n",
       "11  [-0.8456231951713561, -0.12404702603816901, 0....   \n",
       "12  [-0.742057025432586, 0.010221602395176001, 0.2...   \n",
       "13  [-0.8483147025108331, -0.09521148353815001, 0....   \n",
       "14  [-0.7372666597366331, 0.06824257969856201, 0.4...   \n",
       "15  [-0.7887574434280391, -0.095258809626102, 0.09...   \n",
       "\n",
       "                                       characteristic  \n",
       "4   quirky, eclectic, abstract, energetic, passion...  \n",
       "5   introspective, melancholic, energetic, summer,...  \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                                     \n",
       "15                                                     "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recheck df \n",
    "unclean_df.info()\n",
    "unclean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that some records has empty value so we need to process them also\n",
    "clean_df = unclean_df[unclean_df['characteristic']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bhh3_bkx79339d96vvxv8b4h0000gn/T/ipykernel_82580/1013448028.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['characteristic'] = clean_df['characteristic'].apply(filter_and_map_moods)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Characteristics:\n",
      "4                   Energetic/Excited, Mysterious/Abstract\n",
      "5        Sad/Negative, Energetic/Excited, Thoughtful/Co...\n",
      "23       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "24       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "25       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "                               ...                        \n",
      "66526                                                     \n",
      "66527                                                     \n",
      "66528                                                     \n",
      "66529                                                     \n",
      "66530                                                     \n",
      "Name: characteristic, Length: 39697, dtype: object\n",
      "Final DataFrame:\n",
      "                                                  vector  Calm/Peaceful  \\\n",
      "0      [-0.8194460272789, 0.10938329249620402, 0.4214...              0   \n",
      "1      [-0.823113977909088, -0.23747463524341503, 0.2...              0   \n",
      "2      [-0.7328528761863701, 0.077868662774562, 0.301...              1   \n",
      "3      [-0.551648676395416, 0.077182106673717, 0.1172...              1   \n",
      "4      [-0.7803764939308161, 0.030515028163790002, 0....              1   \n",
      "...                                                  ...            ...   \n",
      "39692  [-0.683290839195251, -0.33500030636787403, 0.7...              0   \n",
      "39693  [-0.8331032991409301, 0.18246564269065801, 0.5...              0   \n",
      "39694  [-0.7453204393386841, -0.204361483454704, 0.56...              0   \n",
      "39695  [-0.6801288723945611, -0.2528657913208, 0.5623...              0   \n",
      "39696  [-0.6263767480850221, 0.308717250823974, 0.115...              0   \n",
      "\n",
      "       Dark/Intense  Energetic/Excited  Happy/Positive  Mysterious/Abstract  \\\n",
      "0                 0                  1               0                    1   \n",
      "1                 0                  1               0                    0   \n",
      "2                 0                  0               0                    1   \n",
      "3                 0                  0               0                    1   \n",
      "4                 0                  0               0                    1   \n",
      "...             ...                ...             ...                  ...   \n",
      "39692             0                  0               0                    0   \n",
      "39693             0                  0               0                    0   \n",
      "39694             0                  0               0                    0   \n",
      "39695             0                  0               0                    0   \n",
      "39696             0                  0               0                    0   \n",
      "\n",
      "       Romantic/Emotional  Sad/Negative  Thoughtful/Contemplative  \n",
      "0                       0             0                         0  \n",
      "1                       0             1                         1  \n",
      "2                       1             0                         1  \n",
      "3                       1             0                         1  \n",
      "4                       1             0                         1  \n",
      "...                   ...           ...                       ...  \n",
      "39692                   0             0                         0  \n",
      "39693                   0             0                         0  \n",
      "39694                   0             0                         0  \n",
      "39695                   0             0                         0  \n",
      "39696                   0             0                         0  \n",
      "\n",
      "[39697 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume clean_df is your cleaned DataFrame ready to be processed\n",
    "\n",
    "# Define mood groups\n",
    "mood_groups = {\n",
    "    'aggressive': 'Energetic/Excited', 'energetic': 'Energetic/Excited', 'epic': 'Energetic/Excited', 'noisy': 'Energetic/Excited', 'passionate': 'Energetic/Excited',\n",
    "    'happy': 'Happy/Positive', 'optimistic': 'Happy/Positive', 'playful': 'Energetic/Excited', 'uplifting': 'Happy/Positive',\n",
    "    'calm': 'Calm/Peaceful', 'peaceful': 'Calm/Peaceful', 'soothing': 'Calm/Peaceful', 'meditative': 'Calm/Peaceful', 'soft': 'Calm/Peaceful',\n",
    "    'sad': 'Sad/Negative', 'depressive': 'Sad/Negative', 'melancholic': 'Sad/Negative', 'sombre': 'Sad/Negative', 'pessimistic': 'Sad/Negative', 'lonely': 'Sad/Negative', 'longing': 'Sad/Negative',\n",
    "    'dark': 'Dark/Intense', 'scary': 'Dark/Intense', 'ominous': 'Dark/Intense', 'suspenseful': 'Dark/Intense', 'chaotic': 'Dark/Intense',\n",
    "    'romantic': 'Romantic/Emotional', 'love': 'Romantic/Emotional', 'sensual': 'Romantic/Emotional', 'sentimental': 'Romantic/Emotional', 'sexual': 'Romantic/Emotional',\n",
    "    'introspective': 'Thoughtful/Contemplative', 'existential': 'Thoughtful/Contemplative', 'conscious': 'Thoughtful/Contemplative',\n",
    "    'mysterious': 'Mysterious/Abstract', 'surreal': 'Mysterious/Abstract', 'ethereal': 'Mysterious/Abstract', 'hypnotic': 'Mysterious/Abstract',\n",
    "        'mellow': 'Calm/Peaceful', 'cold': 'Dark/Intense', 'manic': 'Energetic/Excited',  'bittersweet': 'Sad/Negative', 'anxious': 'Dark/Intense','angry': 'Dark/Intense',    'heavy': 'Dark/Intense',    'lush': 'Romantic/Emotional',  'warm': 'Happy/Positive',  'lethargic': 'Sad/Negative', 'eclectic': 'Mysterious/Abstract'\n",
    "}\n",
    "\n",
    "# Define moods to exclude before grouping\n",
    "moods_to_exclude = ['abstract', 'anthemic', 'aquatic', 'boastful', 'breakup', 'cryptic', 'death', 'dense', 'dissonant', 'drugs', 'fantasy', 'futuristic', 'hedonistic',\n",
    "                    'humorous', 'mechanical', 'nature', 'nocturnal', 'orchestral', 'party', 'pastoral', 'poetic', 'psychedelic', 'quirky', 'raw', 'rebellious', 'sarcastic',\n",
    "                    'sparse', 'spiritual', 'spring', 'summer', 'triumphant']\n",
    "\n",
    "# Function to filter and map moods to groups\n",
    "def filter_and_map_moods(moods):\n",
    "    filtered_moods = []\n",
    "    for mood in moods.split(', '):\n",
    "        if mood not in moods_to_exclude and mood in mood_groups:\n",
    "            filtered_moods.append(mood_groups[mood])\n",
    "    result = ', '.join(set(filtered_moods))  # Remove duplicates and convert to string\n",
    "    return result\n",
    "\n",
    "# Apply filtering and mapping to the 'characteristic' column\n",
    "clean_df['characteristic'] = clean_df['characteristic'].apply(filter_and_map_moods)\n",
    "\n",
    "# Check what the 'characteristic' column contains now\n",
    "print(\"Processed Characteristics:\")\n",
    "print(clean_df['characteristic'])\n",
    "# Data is clean, now we will need to turn each of the characteristic into a separate column\n",
    "expanded = clean_df['characteristic'].str.get_dummies(sep=', ')\n",
    "# Merge the expanded characteristic into the old df\n",
    "df = pd.concat([clean_df.drop('characteristic', axis=1), expanded], axis=1)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(\"full_df.csv\")\n",
    "print(\"Final DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['vector', 'aggressive', 'angry', 'anxious', 'bittersweet', 'calm',\n",
      "       'chaotic', 'cold', 'conscious', 'dark', 'depressive', 'eclectic',\n",
      "       'energetic', 'epic', 'ethereal', 'existential', 'happy', 'heavy',\n",
      "       'hypnotic', 'introspective', 'lethargic', 'lonely', 'longing', 'love',\n",
      "       'lush', 'manic', 'meditative', 'melancholic', 'mellow', 'mysterious',\n",
      "       'noisy', 'ominous', 'optimistic', 'passionate', 'peaceful',\n",
      "       'pessimistic', 'playful', 'romantic', 'sad', 'scary', 'sensual',\n",
      "       'sentimental', 'sexual', 'soft', 'sombre', 'soothing', 'surreal',\n",
      "       'suspenseful', 'uplifting', 'warm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Data is clean, now we will need to turn each of the characteristic into a seperate column\n",
    "expanded = clean_df['characteristic'].str.get_dummies(sep=', ')\n",
    "\n",
    "# Merge the expanded characteristic into the old df\n",
    "df = pd.concat([clean_df.drop('characteristic', axis=1), expanded], axis=1)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Choose neccessary columns\n",
    "\n",
    "columns_to_exclude = ['abstract', 'anthemic', 'aquatic', 'boastful', 'breakup', 'cryptic', 'death', 'dense', 'dissonant', 'drugs', 'fantasy', 'futuristic', 'hedonistic',\n",
    "                      'humorous', 'mechanical', 'nature', 'nocturnal', 'orchestral', 'party', 'pastoral', 'poetic', 'psychedelic', 'quirky', 'raw', 'rebellious', 'sarcastic',\n",
    "                      'sparse', 'spiritual', 'spring', 'summer', 'triumphant']\n",
    "\n",
    "df = df.drop(columns=columns_to_exclude,axis=1)\n",
    "\n",
    "print(df.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume df['vector'] contains lists of vectors and df.iloc[:,1:] contains the labels\n",
    "\n",
    "# Convert lists of vectors into a numpy array\n",
    "X = np.stack(df['vector'].values)\n",
    "\n",
    "# Extract labels\n",
    "y = df.iloc[:,1:].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform it\n",
    "#X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data with the same scaler\n",
    "#X_test = scaler.transform(X_test)\n",
    "\n",
    "# Your data is now normalized and ready for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Apply SMOTE\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m X_smote, y_smote \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/base.py:160\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accept_sparse \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     accept_sparse \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 160\u001b[0m y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    161\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, binarize_y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py:156\u001b[0m, in \u001b[0;36mcheck_target_type\u001b[0;34m(y, indicate_one_vs_all)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImbalanced-learn currently supports binary, multiclass and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinarized encoded multiclasss targets. Multilabel and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultioutput targets are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[1;32m    161\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported."
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.05327455919395466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Wrap the classifier in MultiOutputClassifier for multi-label classification\n",
    "multi_label_classifier = MultiOutputClassifier(classifier, n_jobs=-1)\n",
    "\n",
    "# Train the multi-label classifier\n",
    "multi_label_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = multi_label_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0681360201511335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC(kernel='linear', probability=True, random_state = 42)\n",
    "\n",
    "# Wrap the classifier in MultiOutputClassifier for multi-label classification\n",
    "svm_multi_label_classifier = MultiOutputClassifier(svm_classifier, n_jobs=-1)\n",
    "\n",
    "# Train the multi-label classifier\n",
    "svm_multi_label_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_svm = svm_multi_label_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy of the predictions\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11309823677581864"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Label Powerset\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "# initialize Label Powerset multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = LabelPowerset(SVC(kernel='linear', random_state = 42))\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with RBF kernel: 0.10188916876574307\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "\n",
    "# Initialize SVM classifier with RBF kernel\n",
    "svm_classifier = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "# Initialize Label Powerset multi-label classifier with the SVM classifier\n",
    "lp_classifier = LabelPowerset(classifier=svm_classifier)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "lp_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lp_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with RBF kernel:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] END classifier__C=0.2938027938703535, classifier__gamma=0.16959629191460518; total time= 7.2min\n",
      "[CV] END classifier__C=0.2938027938703535, classifier__gamma=0.16959629191460518; total time= 7.2min\n",
      "[CV] END classifier__C=0.2938027938703535, classifier__gamma=0.16959629191460518; total time= 7.2min\n",
      "[CV] END classifier__C=15.702970884055382, classifier__gamma=0.9129425537759532; total time=12.6min\n",
      "[CV] END classifier__C=15.702970884055382, classifier__gamma=0.9129425537759532; total time=12.6min\n",
      "[CV] END classifier__C=15.702970884055382, classifier__gamma=0.9129425537759532; total time=12.7min\n",
      "[CV] END classifier__C=0.14936568554617632, classifier__gamma=2.0112308644799395; total time=13.0min\n",
      "[CV] END classifier__C=1.3292918943162166, classifier__gamma=3.010121430917521; total time=13.3min\n",
      "[CV] END classifier__C=1.3292918943162166, classifier__gamma=3.010121430917521; total time=13.3min\n",
      "[CV] END classifier__C=1.3292918943162166, classifier__gamma=3.010121430917521; total time=13.4min\n",
      "[CV] END classifier__C=0.14936568554617632, classifier__gamma=2.0112308644799395; total time=12.1min\n",
      "[CV] END classifier__C=6.358358856676251, classifier__gamma=1.2312500617045903; total time=12.1min\n",
      "[CV] END classifier__C=0.14936568554617632, classifier__gamma=2.0112308644799395; total time=12.2min\n",
      "[CV] END classifier__C=6.358358856676251, classifier__gamma=1.2312500617045903; total time=10.7min\n",
      "[CV] END classifier__C=6.358358856676251, classifier__gamma=1.2312500617045903; total time=10.9min\n",
      "Best Parameters: {'classifier__C': 15.702970884055382, 'classifier__gamma': 0.9129425537759532}\n",
      "Best Score: 0.13323050086829594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "# Define the parameter distributions rather than a parameter grid\n",
    "param_distributions = {\n",
    "    'classifier__C': reciprocal(0.1, 100),\n",
    "    'classifier__gamma': expon(scale=1.0)\n",
    "}\n",
    "\n",
    "# Initialize the randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lp_classifier, \n",
    "    param_distributions=param_distributions, \n",
    "    n_iter=5,  # The number of parameter settings that are sampled, reduce if necessary\n",
    "    cv=3, \n",
    "    verbose=2, \n",
    "    random_state=42, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Perform randomized search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "best_parameters = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "print(\"Best Parameters:\", best_parameters)\n",
    "print(\"Best Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(128,)),  # First hidden layer\n",
    "    Dense(64, activation='relu'),                        # Second hidden layer\n",
    "    Dense(8, activation='sigmoid')                       # Output layer with 8 nodes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(128,)),  # Increase neurons\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),  # Adjust dropout rate\n",
    "    \n",
    "    Dense(128, activation='relu'),  # Add an additional layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(64, activation='relu'),  # Existing layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(32, activation='relu'),  # Add an additional layer\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Dense(8, activation='sigmoid')  # Output layer with 8 nodes\n",
    "])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 637us/step - accuracy: 0.2681 - loss: 0.5043 - val_accuracy: 0.2271 - val_loss: 0.5568\n",
      "Epoch 2/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.2669 - loss: 0.5075 - val_accuracy: 0.2389 - val_loss: 0.5522\n",
      "Epoch 3/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.2669 - loss: 0.5037 - val_accuracy: 0.2293 - val_loss: 0.5567\n",
      "Epoch 4/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.2714 - loss: 0.5048 - val_accuracy: 0.2275 - val_loss: 0.5529\n",
      "Epoch 5/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606us/step - accuracy: 0.2651 - loss: 0.5047 - val_accuracy: 0.2270 - val_loss: 0.5575\n",
      "Epoch 6/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.2710 - loss: 0.5026 - val_accuracy: 0.2345 - val_loss: 0.5538\n",
      "Epoch 7/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - accuracy: 0.2695 - loss: 0.5039 - val_accuracy: 0.2445 - val_loss: 0.5609\n",
      "Epoch 8/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 614us/step - accuracy: 0.2650 - loss: 0.5029 - val_accuracy: 0.2331 - val_loss: 0.5547\n",
      "Epoch 9/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.2717 - loss: 0.5051 - val_accuracy: 0.2411 - val_loss: 0.5554\n",
      "Epoch 10/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 654us/step - accuracy: 0.2718 - loss: 0.5017 - val_accuracy: 0.2487 - val_loss: 0.5643\n",
      "Epoch 11/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.2728 - loss: 0.5015 - val_accuracy: 0.2336 - val_loss: 0.5600\n",
      "Epoch 12/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624us/step - accuracy: 0.2742 - loss: 0.5000 - val_accuracy: 0.2409 - val_loss: 0.5621\n",
      "Epoch 13/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.2740 - loss: 0.4998 - val_accuracy: 0.2366 - val_loss: 0.5603\n",
      "Epoch 14/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609us/step - accuracy: 0.2726 - loss: 0.4992 - val_accuracy: 0.2363 - val_loss: 0.5579\n",
      "Epoch 15/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.2733 - loss: 0.4999 - val_accuracy: 0.2509 - val_loss: 0.5667\n",
      "Epoch 16/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.2703 - loss: 0.4968 - val_accuracy: 0.2606 - val_loss: 0.5623\n",
      "Epoch 17/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.2774 - loss: 0.4983 - val_accuracy: 0.2351 - val_loss: 0.5597\n",
      "Epoch 18/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 635us/step - accuracy: 0.2723 - loss: 0.4954 - val_accuracy: 0.2530 - val_loss: 0.5593\n",
      "Epoch 19/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 621us/step - accuracy: 0.2779 - loss: 0.4963 - val_accuracy: 0.2583 - val_loss: 0.5621\n",
      "Epoch 20/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.2768 - loss: 0.4930 - val_accuracy: 0.2350 - val_loss: 0.5600\n",
      "Epoch 21/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 618us/step - accuracy: 0.2761 - loss: 0.4929 - val_accuracy: 0.2283 - val_loss: 0.5570\n",
      "Epoch 22/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.2793 - loss: 0.4942 - val_accuracy: 0.2360 - val_loss: 0.5602\n",
      "Epoch 23/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630us/step - accuracy: 0.2798 - loss: 0.4953 - val_accuracy: 0.2310 - val_loss: 0.5625\n",
      "Epoch 24/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.2769 - loss: 0.4930 - val_accuracy: 0.2348 - val_loss: 0.5646\n",
      "Epoch 25/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.2773 - loss: 0.4910 - val_accuracy: 0.2392 - val_loss: 0.5692\n",
      "Epoch 26/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.2749 - loss: 0.4941 - val_accuracy: 0.2330 - val_loss: 0.5645\n",
      "Epoch 27/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 605us/step - accuracy: 0.2752 - loss: 0.4916 - val_accuracy: 0.2557 - val_loss: 0.5652\n",
      "Epoch 28/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 585us/step - accuracy: 0.2803 - loss: 0.4929 - val_accuracy: 0.2356 - val_loss: 0.5657\n",
      "Epoch 29/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603us/step - accuracy: 0.2748 - loss: 0.4912 - val_accuracy: 0.2496 - val_loss: 0.5678\n",
      "Epoch 30/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 617us/step - accuracy: 0.2733 - loss: 0.4924 - val_accuracy: 0.2349 - val_loss: 0.5643\n",
      "Epoch 31/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.2795 - loss: 0.4911 - val_accuracy: 0.2377 - val_loss: 0.5675\n",
      "Epoch 32/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.2827 - loss: 0.4888 - val_accuracy: 0.2356 - val_loss: 0.5706\n",
      "Epoch 33/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.2797 - loss: 0.4899 - val_accuracy: 0.2407 - val_loss: 0.5729\n",
      "Epoch 34/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.2834 - loss: 0.4867 - val_accuracy: 0.2412 - val_loss: 0.5644\n",
      "Epoch 35/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 575us/step - accuracy: 0.2844 - loss: 0.4895 - val_accuracy: 0.2350 - val_loss: 0.5691\n",
      "Epoch 36/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.2853 - loss: 0.4883 - val_accuracy: 0.2462 - val_loss: 0.5783\n",
      "Epoch 37/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569us/step - accuracy: 0.2811 - loss: 0.4872 - val_accuracy: 0.2494 - val_loss: 0.5714\n",
      "Epoch 38/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608us/step - accuracy: 0.2831 - loss: 0.4887 - val_accuracy: 0.2372 - val_loss: 0.5677\n",
      "Epoch 39/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.2805 - loss: 0.4878 - val_accuracy: 0.2215 - val_loss: 0.5690\n",
      "Epoch 40/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.2784 - loss: 0.4862 - val_accuracy: 0.2489 - val_loss: 0.5711\n",
      "Epoch 41/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.2868 - loss: 0.4882 - val_accuracy: 0.2416 - val_loss: 0.5728\n",
      "Epoch 42/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.2847 - loss: 0.4872 - val_accuracy: 0.2258 - val_loss: 0.5731\n",
      "Epoch 43/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.2870 - loss: 0.4862 - val_accuracy: 0.2266 - val_loss: 0.5722\n",
      "Epoch 44/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.2800 - loss: 0.4856 - val_accuracy: 0.2602 - val_loss: 0.5759\n",
      "Epoch 45/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 568us/step - accuracy: 0.2904 - loss: 0.4833 - val_accuracy: 0.2387 - val_loss: 0.5718\n",
      "Epoch 46/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 574us/step - accuracy: 0.2850 - loss: 0.4855 - val_accuracy: 0.2366 - val_loss: 0.5719\n",
      "Epoch 47/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597us/step - accuracy: 0.2905 - loss: 0.4828 - val_accuracy: 0.2385 - val_loss: 0.5753\n",
      "Epoch 48/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 583us/step - accuracy: 0.2837 - loss: 0.4833 - val_accuracy: 0.2368 - val_loss: 0.5757\n",
      "Epoch 49/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.2821 - loss: 0.4834 - val_accuracy: 0.2300 - val_loss: 0.5740\n",
      "Epoch 50/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.2866 - loss: 0.4836 - val_accuracy: 0.2395 - val_loss: 0.5747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x38901d910>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                  classes=np.unique(y_train),\n",
    "                                                  y=y_train.flatten())\n",
    "\n",
    "# Convert class weights to a dictionary to pass to Keras\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# Use class weights in model training\n",
    "model.fit(X_train, y_train, class_weight=class_weight_dict, epochs=50, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels list to match with the array\n",
    "\n",
    "columns_list = list(df.columns)\n",
    "\n",
    "labels = columns_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304us/step\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           Calm/Peaceful       0.65      0.30      0.41      2390\n",
      "            Dark/Intense       0.48      0.38      0.42      1581\n",
      "       Energetic/Excited       0.62      0.53      0.58      2743\n",
      "          Happy/Positive       0.55      0.43      0.48      2862\n",
      "     Mysterious/Abstract       0.57      0.37      0.45      2691\n",
      "      Romantic/Emotional       0.59      0.56      0.58      3223\n",
      "            Sad/Negative       0.57      0.46      0.51      2937\n",
      "Thoughtful/Contemplative       0.53      0.19      0.28      1822\n",
      "\n",
      "               micro avg       0.58      0.42      0.49     20249\n",
      "               macro avg       0.57      0.40      0.46     20249\n",
      "            weighted avg       0.58      0.42      0.48     20249\n",
      "             samples avg       0.55      0.43      0.45     20249\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict labels for the validation set\n",
    "predictions = model.predict(X_test) > 0.5  # Apply threshold to get binary outputs\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, predictions, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first record in test data\n",
    "flattened_array=predictions[2].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calm/Peaceful', 'Dark/Intense', 'Energetic/Excited', 'Happy/Positive', 'Mysterious/Abstract', 'Romantic/Emotional', 'Sad/Negative', 'Thoughtful/Contemplative']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy/Positive', 'Sad/Negative']\n"
     ]
    }
   ],
   "source": [
    "# Choose index where value is 1\n",
    "indices_with_ones = [index for index, value in enumerate(flattened_array) if value == 1]\n",
    "\n",
    "# Map indices to labels\n",
    "selected_labels = [labels[index] for index in indices_with_ones]\n",
    "\n",
    "print(selected_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracy, we will use the LabelPowerSet transform and SVM as the model to predict songs' characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['multi_char_classifier.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(classifier, 'multi_char_classifier.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model, file)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'Layer._initialize_tracker.<locals>.<lambda>'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('nn_model.pkl', 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
