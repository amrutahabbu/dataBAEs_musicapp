{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML packages\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json file\n",
    "original_df = pd.read_json(\"/Users/bach/Documents/MP3-Project/complete_df_creation/music_vector_metadata.json\")\n",
    "\n",
    "# Because there are duplicates in column name so we will drop it\n",
    "original_df.drop_duplicates(subset=['track_id'],inplace=True)\n",
    "\n",
    "# We only take vector and characteristic columns\n",
    "unclean_df = original_df[['vector', 'characteristic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bhh3_bkx79339d96vvxv8b4h0000gn/T/ipykernel_82580/907424595.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unclean_df.dropna(subset=['characteristic'], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "# Drop N/A values in the characteristic\n",
    "unclean_df.dropna(subset=['characteristic'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that some records has empty value so we need to process them also\n",
    "clean_df = unclean_df[unclean_df['characteristic']!='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Characteristics:\n",
      "4                   Energetic/Excited, Mysterious/Abstract\n",
      "5        Sad/Negative, Energetic/Excited, Thoughtful/Co...\n",
      "23       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "24       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "25       Calm/Peaceful, Romantic/Emotional, Mysterious/...\n",
      "                               ...                        \n",
      "66526                                                     \n",
      "66527                                                     \n",
      "66528                                                     \n",
      "66529                                                     \n",
      "66530                                                     \n",
      "Name: characteristic, Length: 39697, dtype: object\n",
      "Final DataFrame:\n",
      "                                                  vector  Calm/Peaceful  \\\n",
      "0      [-0.8194460272789, 0.10938329249620402, 0.4214...              0   \n",
      "1      [-0.823113977909088, -0.23747463524341503, 0.2...              0   \n",
      "2      [-0.7328528761863701, 0.077868662774562, 0.301...              1   \n",
      "3      [-0.551648676395416, 0.077182106673717, 0.1172...              1   \n",
      "4      [-0.7803764939308161, 0.030515028163790002, 0....              1   \n",
      "...                                                  ...            ...   \n",
      "39692  [-0.683290839195251, -0.33500030636787403, 0.7...              0   \n",
      "39693  [-0.8331032991409301, 0.18246564269065801, 0.5...              0   \n",
      "39694  [-0.7453204393386841, -0.204361483454704, 0.56...              0   \n",
      "39695  [-0.6801288723945611, -0.2528657913208, 0.5623...              0   \n",
      "39696  [-0.6263767480850221, 0.308717250823974, 0.115...              0   \n",
      "\n",
      "       Dark/Intense  Energetic/Excited  Happy/Positive  Mysterious/Abstract  \\\n",
      "0                 0                  1               0                    1   \n",
      "1                 0                  1               0                    0   \n",
      "2                 0                  0               0                    1   \n",
      "3                 0                  0               0                    1   \n",
      "4                 0                  0               0                    1   \n",
      "...             ...                ...             ...                  ...   \n",
      "39692             0                  0               0                    0   \n",
      "39693             0                  0               0                    0   \n",
      "39694             0                  0               0                    0   \n",
      "39695             0                  0               0                    0   \n",
      "39696             0                  0               0                    0   \n",
      "\n",
      "       Romantic/Emotional  Sad/Negative  Thoughtful/Contemplative  \n",
      "0                       0             0                         0  \n",
      "1                       0             1                         1  \n",
      "2                       1             0                         1  \n",
      "3                       1             0                         1  \n",
      "4                       1             0                         1  \n",
      "...                   ...           ...                       ...  \n",
      "39692                   0             0                         0  \n",
      "39693                   0             0                         0  \n",
      "39694                   0             0                         0  \n",
      "39695                   0             0                         0  \n",
      "39696                   0             0                         0  \n",
      "\n",
      "[39697 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/bhh3_bkx79339d96vvxv8b4h0000gn/T/ipykernel_82580/1047655510.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['characteristic'] = clean_df['characteristic'].apply(filter_and_map_moods)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assume clean_df is your cleaned DataFrame ready to be processed\n",
    "\n",
    "# Define mood groups\n",
    "mood_groups = {\n",
    "    'aggressive': 'Energetic/Excited', 'energetic': 'Energetic/Excited', 'epic': 'Energetic/Excited', 'noisy': 'Energetic/Excited', 'passionate': 'Energetic/Excited',\n",
    "    'happy': 'Happy/Positive', 'optimistic': 'Happy/Positive', 'playful': 'Energetic/Excited', 'uplifting': 'Happy/Positive',\n",
    "    'calm': 'Calm/Peaceful', 'peaceful': 'Calm/Peaceful', 'soothing': 'Calm/Peaceful', 'meditative': 'Calm/Peaceful', 'soft': 'Calm/Peaceful',\n",
    "    'sad': 'Sad/Negative', 'depressive': 'Sad/Negative', 'melancholic': 'Sad/Negative', 'sombre': 'Sad/Negative', 'pessimistic': 'Sad/Negative', 'lonely': 'Sad/Negative', 'longing': 'Sad/Negative',\n",
    "    'dark': 'Dark/Intense', 'scary': 'Dark/Intense', 'ominous': 'Dark/Intense', 'suspenseful': 'Dark/Intense', 'chaotic': 'Dark/Intense',\n",
    "    'romantic': 'Romantic/Emotional', 'love': 'Romantic/Emotional', 'sensual': 'Romantic/Emotional', 'sentimental': 'Romantic/Emotional', 'sexual': 'Romantic/Emotional',\n",
    "    'introspective': 'Thoughtful/Contemplative', 'existential': 'Thoughtful/Contemplative', 'conscious': 'Thoughtful/Contemplative',\n",
    "    'mysterious': 'Mysterious/Abstract', 'surreal': 'Mysterious/Abstract', 'ethereal': 'Mysterious/Abstract', 'hypnotic': 'Mysterious/Abstract',\n",
    "        'mellow': 'Calm/Peaceful', 'cold': 'Dark/Intense', 'manic': 'Energetic/Excited',  'bittersweet': 'Sad/Negative', 'anxious': 'Dark/Intense','angry': 'Dark/Intense',    'heavy': 'Dark/Intense',    'lush': 'Romantic/Emotional',  'warm': 'Happy/Positive',  'lethargic': 'Sad/Negative', 'eclectic': 'Mysterious/Abstract'\n",
    "}\n",
    "\n",
    "# Define moods to exclude before grouping\n",
    "moods_to_exclude = ['abstract', 'anthemic', 'aquatic', 'boastful', 'breakup', 'cryptic', 'death', 'dense', 'dissonant', 'drugs', 'fantasy', 'futuristic', 'hedonistic',\n",
    "                    'humorous', 'mechanical', 'nature', 'nocturnal', 'orchestral', 'party', 'pastoral', 'poetic', 'psychedelic', 'quirky', 'raw', 'rebellious', 'sarcastic',\n",
    "                    'sparse', 'spiritual', 'spring', 'summer', 'triumphant']\n",
    "\n",
    "# Function to filter and map moods to groups\n",
    "def filter_and_map_moods(moods):\n",
    "    filtered_moods = []\n",
    "    for mood in moods.split(', '):\n",
    "        if mood not in moods_to_exclude and mood in mood_groups:\n",
    "            filtered_moods.append(mood_groups[mood])\n",
    "    result = ', '.join(set(filtered_moods))  # Remove duplicates and convert to string\n",
    "    return result\n",
    "\n",
    "# Apply filtering and mapping to the 'characteristic' column\n",
    "clean_df['characteristic'] = clean_df['characteristic'].apply(filter_and_map_moods)\n",
    "\n",
    "# Check what the 'characteristic' column contains now\n",
    "print(\"Processed Characteristics:\")\n",
    "print(clean_df['characteristic'])\n",
    "# Data is clean, now we will need to turn each of the characteristic into a separate column\n",
    "expanded = clean_df['characteristic'].str.get_dummies(sep=', ')\n",
    "# Merge the expanded characteristic into the old df\n",
    "df = pd.concat([clean_df.drop('characteristic', axis=1), expanded], axis=1)\n",
    "\n",
    "# Reset index\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"Final DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume df['vector'] contains lists of vectors and df.iloc[:,1:] contains the labels\n",
    "\n",
    "# Convert lists of vectors into a numpy array\n",
    "X = np.stack(df['vector'].values)\n",
    "\n",
    "# Extract labels\n",
    "y = df.iloc[:,1:].values\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(128,)),  # First hidden layer\n",
    "    Dense(64, activation='relu'),                        # Second hidden layer\n",
    "    Dense(8, activation='sigmoid')                       # Output layer with 8 nodes\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_weights(y, class_weights):\n",
    "    # Initialize sample weights with ones\n",
    "    sample_weights = np.ones(shape=(y.shape[0],))\n",
    "    \n",
    "    # Iterate through all the class weights and apply them to the sample weights\n",
    "    for class_index, weight in class_weights.items():\n",
    "        # Apply class weight by multiplying the sample weight by the class weight where the label is present\n",
    "        sample_weights *= np.where(y[:, class_index] == 1, weight, 1)\n",
    "    \n",
    "    return sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step - accuracy: 0.2624 - loss: 1.1382 - val_accuracy: 0.2399 - val_loss: 0.5613\n",
      "Epoch 2/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 588us/step - accuracy: 0.2791 - loss: 1.0837 - val_accuracy: 0.3057 - val_loss: 0.5556\n",
      "Epoch 3/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 578us/step - accuracy: 0.2815 - loss: 1.0795 - val_accuracy: 0.2846 - val_loss: 0.5608\n",
      "Epoch 4/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 615us/step - accuracy: 0.2835 - loss: 1.0709 - val_accuracy: 0.2901 - val_loss: 0.5526\n",
      "Epoch 5/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577us/step - accuracy: 0.2789 - loss: 1.0767 - val_accuracy: 0.2966 - val_loss: 0.5560\n",
      "Epoch 6/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.2807 - loss: 1.0627 - val_accuracy: 0.2940 - val_loss: 0.5624\n",
      "Epoch 7/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 594us/step - accuracy: 0.2828 - loss: 1.0701 - val_accuracy: 0.2668 - val_loss: 0.5537\n",
      "Epoch 8/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - accuracy: 0.2746 - loss: 1.0581 - val_accuracy: 0.2666 - val_loss: 0.5473\n",
      "Epoch 9/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.2798 - loss: 1.0528 - val_accuracy: 0.2864 - val_loss: 0.5504\n",
      "Epoch 10/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.2838 - loss: 1.0560 - val_accuracy: 0.2797 - val_loss: 0.5524\n",
      "Epoch 11/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 667us/step - accuracy: 0.2804 - loss: 1.0567 - val_accuracy: 0.3176 - val_loss: 0.5499\n",
      "Epoch 12/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.2849 - loss: 1.0519 - val_accuracy: 0.2820 - val_loss: 0.5488\n",
      "Epoch 13/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 582us/step - accuracy: 0.2839 - loss: 1.0418 - val_accuracy: 0.2778 - val_loss: 0.5526\n",
      "Epoch 14/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 655us/step - accuracy: 0.2890 - loss: 1.0335 - val_accuracy: 0.2714 - val_loss: 0.5537\n",
      "Epoch 15/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.2815 - loss: 1.0364 - val_accuracy: 0.2791 - val_loss: 0.5497\n",
      "Epoch 16/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 564us/step - accuracy: 0.2899 - loss: 1.0367 - val_accuracy: 0.2741 - val_loss: 0.5515\n",
      "Epoch 17/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.2885 - loss: 1.0335 - val_accuracy: 0.2752 - val_loss: 0.5482\n",
      "Epoch 18/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 573us/step - accuracy: 0.2865 - loss: 1.0301 - val_accuracy: 0.2798 - val_loss: 0.5489\n",
      "Epoch 19/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581us/step - accuracy: 0.2937 - loss: 1.0247 - val_accuracy: 0.2758 - val_loss: 0.5505\n",
      "Epoch 20/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562us/step - accuracy: 0.2954 - loss: 1.0218 - val_accuracy: 0.2557 - val_loss: 0.5507\n",
      "Epoch 21/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596us/step - accuracy: 0.2881 - loss: 1.0284 - val_accuracy: 0.2883 - val_loss: 0.5523\n",
      "Epoch 22/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 555us/step - accuracy: 0.2910 - loss: 1.0271 - val_accuracy: 0.2661 - val_loss: 0.5534\n",
      "Epoch 23/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.2894 - loss: 1.0253 - val_accuracy: 0.2860 - val_loss: 0.5551\n",
      "Epoch 24/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.2880 - loss: 1.0124 - val_accuracy: 0.2693 - val_loss: 0.5492\n",
      "Epoch 25/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 563us/step - accuracy: 0.2929 - loss: 1.0113 - val_accuracy: 0.2806 - val_loss: 0.5507\n",
      "Epoch 26/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586us/step - accuracy: 0.2928 - loss: 1.0138 - val_accuracy: 0.2792 - val_loss: 0.5523\n",
      "Epoch 27/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553us/step - accuracy: 0.2943 - loss: 1.0144 - val_accuracy: 0.2730 - val_loss: 0.5543\n",
      "Epoch 28/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556us/step - accuracy: 0.2927 - loss: 1.0131 - val_accuracy: 0.2759 - val_loss: 0.5524\n",
      "Epoch 29/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591us/step - accuracy: 0.2909 - loss: 1.0199 - val_accuracy: 0.2872 - val_loss: 0.5545\n",
      "Epoch 30/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.2924 - loss: 1.0076 - val_accuracy: 0.2795 - val_loss: 0.5606\n",
      "Epoch 31/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 552us/step - accuracy: 0.3001 - loss: 1.0057 - val_accuracy: 0.2843 - val_loss: 0.5509\n",
      "Epoch 32/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 587us/step - accuracy: 0.2967 - loss: 1.0004 - val_accuracy: 0.2893 - val_loss: 0.5523\n",
      "Epoch 33/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559us/step - accuracy: 0.3027 - loss: 1.0007 - val_accuracy: 0.2856 - val_loss: 0.5494\n",
      "Epoch 34/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.3025 - loss: 0.9977 - val_accuracy: 0.2898 - val_loss: 0.5593\n",
      "Epoch 35/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 648us/step - accuracy: 0.2999 - loss: 1.0026 - val_accuracy: 0.2899 - val_loss: 0.5510\n",
      "Epoch 36/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 571us/step - accuracy: 0.3079 - loss: 0.9969 - val_accuracy: 0.2943 - val_loss: 0.5550\n",
      "Epoch 37/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566us/step - accuracy: 0.3092 - loss: 0.9972 - val_accuracy: 0.2608 - val_loss: 0.5536\n",
      "Epoch 38/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 600us/step - accuracy: 0.3027 - loss: 0.9978 - val_accuracy: 0.2655 - val_loss: 0.5536\n",
      "Epoch 39/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 554us/step - accuracy: 0.3053 - loss: 0.9945 - val_accuracy: 0.2940 - val_loss: 0.5516\n",
      "Epoch 40/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.3104 - loss: 0.9871 - val_accuracy: 0.2863 - val_loss: 0.5634\n",
      "Epoch 41/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 599us/step - accuracy: 0.3036 - loss: 0.9835 - val_accuracy: 0.2935 - val_loss: 0.5523\n",
      "Epoch 42/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557us/step - accuracy: 0.3071 - loss: 0.9813 - val_accuracy: 0.2918 - val_loss: 0.5545\n",
      "Epoch 43/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 550us/step - accuracy: 0.3076 - loss: 0.9880 - val_accuracy: 0.2466 - val_loss: 0.5623\n",
      "Epoch 44/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 595us/step - accuracy: 0.3014 - loss: 0.9890 - val_accuracy: 0.2683 - val_loss: 0.5582\n",
      "Epoch 45/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 567us/step - accuracy: 0.3050 - loss: 0.9788 - val_accuracy: 0.2849 - val_loss: 0.5586\n",
      "Epoch 46/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 558us/step - accuracy: 0.3076 - loss: 0.9740 - val_accuracy: 0.2901 - val_loss: 0.5615\n",
      "Epoch 47/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 601us/step - accuracy: 0.3122 - loss: 0.9782 - val_accuracy: 0.2661 - val_loss: 0.5630\n",
      "Epoch 48/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576us/step - accuracy: 0.3007 - loss: 0.9793 - val_accuracy: 0.2952 - val_loss: 0.5618\n",
      "Epoch 49/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 580us/step - accuracy: 0.3139 - loss: 0.9781 - val_accuracy: 0.2816 - val_loss: 0.5583\n",
      "Epoch 50/50\n",
      "\u001b[1m993/993\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 622us/step - accuracy: 0.3041 - loss: 0.9772 - val_accuracy: 0.2591 - val_loss: 0.5654\n"
     ]
    }
   ],
   "source": [
    "# Your pre-computed class weights\n",
    "pre_computed_class_weights = {\n",
    "    'Calm/Peaceful': 1.3485355648535564, \n",
    "    'Dark/Intense': 2.038583175205566, \n",
    "    'Energetic/Excited': 1.1749908858913598, \n",
    "    'Happy/Positive': 1.126135569531796, \n",
    "    'Mysterious/Abstract': 1.1976960237829803, \n",
    "    'Romantic/Emotional': 1.0, \n",
    "    'Sad/Negative': 1.097378277153558, \n",
    "    'Thoughtful/Contemplative': 1.7689352360043908\n",
    "}\n",
    "\n",
    "# Convert the class weights to indices (assuming the order of your output layer matches the dictionary keys)\n",
    "class_weight_indices = {i: pre_computed_class_weights[label] for i, label in enumerate(pre_computed_class_weights)}\n",
    "\n",
    "# Calculate sample weights\n",
    "sample_weights = calculate_sample_weights(y_train, class_weight_indices)\n",
    "\n",
    "# Now fit the model with sample weights\n",
    "history = model.fit(\n",
    "    X_train, y_train, \n",
    "    sample_weight=sample_weights, \n",
    "    epochs=50, \n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create labels list to match with the array\n",
    "\n",
    "columns_list = list(df.columns)\n",
    "\n",
    "labels = columns_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m249/249\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341us/step\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "           Calm/Peaceful       0.62      0.38      0.48      2390\n",
      "            Dark/Intense       0.46      0.44      0.45      1581\n",
      "       Energetic/Excited       0.68      0.56      0.62      3464\n",
      "          Happy/Positive       0.53      0.12      0.19      2097\n",
      "     Mysterious/Abstract       0.55      0.45      0.49      2691\n",
      "      Romantic/Emotional       0.60      0.52      0.56      3223\n",
      "            Sad/Negative       0.52      0.62      0.56      2937\n",
      "Thoughtful/Contemplative       0.38      0.42      0.40      1822\n",
      "\n",
      "               micro avg       0.55      0.46      0.50     20205\n",
      "               macro avg       0.54      0.44      0.47     20205\n",
      "            weighted avg       0.56      0.46      0.49     20205\n",
      "             samples avg       0.54      0.47      0.47     20205\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict labels for the validation set\n",
    "predictions = model.predict(X_test) > 0.5  # Apply threshold to get binary outputs\n",
    "\n",
    "# Print detailed classification report\n",
    "print(classification_report(y_test, predictions, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first record in test data\n",
    "flattened_array=predictions[0].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Calm/Peaceful', 'Dark/Intense', 'Energetic/Excited', 'Happy/Positive', 'Mysterious/Abstract', 'Romantic/Emotional', 'Sad/Negative', 'Thoughtful/Contemplative']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Energetic/Excited', 'Mysterious/Abstract', 'Sad/Negative', 'Thoughtful/Contemplative']\n"
     ]
    }
   ],
   "source": [
    "# Choose index where value is 1\n",
    "indices_with_ones = [index for index, value in enumerate(flattened_array) if value == 1]\n",
    "\n",
    "# Map indices to labels\n",
    "selected_labels = [labels[index] for index in indices_with_ones]\n",
    "\n",
    "print(selected_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the accuracy, we will use the LabelPowerSet transform and SVM as the model to predict songs' characteristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('data/NN_feature2.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
